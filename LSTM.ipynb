{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da666dfb-4353-4f4e-8614-47e3baa2d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acbd438-2ff2-48f4-91c1-7704f7d6634b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword        location  \\\n",
       "0   0  ablaze             NaN   \n",
       "1   1  ablaze             NaN   \n",
       "2   2  ablaze   New York City   \n",
       "3   3  ablaze  Morgantown, WV   \n",
       "4   4  ablaze             NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster = pd.read_csv('C:/Users/Dikshant Gupta/Desktop/VIT/SEM 6/CSE3020_DV_Prj_NIL/data/tweets.csv')\n",
    "disaster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a6d0c3-03d5-44e5-8ed9-a3298687d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
       "1  Telangana: Section 144 has been imposed in Bha...       1\n",
       "2  Arsonist sets cars ablaze at dealership https:...       1\n",
       "3  Arsonist sets cars ablaze at dealership https:...       1\n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading required features\n",
    "disaster = disaster[['text','target']]\n",
    "disaster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ff29c0-a0c6-4914-94bf-b628c986ae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    communal violence in bhainsa, telangana. \"ston...\n",
       "1    telangana: section 144 has been imposed in bha...\n",
       "2    arsonist sets cars ablaze at dealership https:...\n",
       "3    arsonist sets cars ablaze at dealership https:...\n",
       "4    \"lord jesus, your love brings freedom and pard...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster['text'] = [entry.lower() for entry in disaster['text']]\n",
    "disaster['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ac7cea-1801-4efb-a1a9-2ba226db34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages for Tokenzation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b341c13-a720-4e56-8ae5-b83164cc108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster['text'] = [word_tokenize(entry) for entry in disaster['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb1a65c-5e92-4937-aa42-4fa5446e85b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [communal, violence, in, bhainsa, ,, telangana...\n",
       "1    [telangana, :, section, 144, has, been, impose...\n",
       "2    [arsonist, sets, cars, ablaze, at, dealership,...\n",
       "3    [arsonist, sets, cars, ablaze, at, dealership,...\n",
       "4    [``, lord, jesus, ,, your, love, brings, freed...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5dfa0d-f44d-46c2-984c-e103fcb5fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS & Stemming\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f2c895-00b5-4bd4-b1d6-2a5bd1eeadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['j'] = wn.ADJ\n",
    "tag_map['v'] = wn.VERB\n",
    "tag_map['v'] = wn.ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b6be96-7a18-4037-8248-d4cd531703a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'but', 'whom', \"isn't\", \"shouldn't\", \"couldn't\", 'be', \"shan't\", 'does', 'wasn', 'after', 'if', 'his', 'd', 'he', 'wouldn', \"wasn't\", 's', \"hasn't\", 'while', 'few', 'during', 'own', 'how', 'no', 'themselves', 'weren', 'did', 'myself', \"won't\", 'she', 'her', 'on', 'off', 'those', 'will', \"doesn't\", 'himself', 'nor', 'up', 'an', 'about', \"aren't\", 'out', 'what', 'isn', 'do', 'only', 'him', 'by', 'both', 'which', 'is', 'again', 'as', 'itself', 'yourself', \"don't\", 'where', \"you've\", 'now', 'shouldn', 't', 'through', 'were', 'been', 'such', \"should've\", 'ma', 'some', 'hasn', 'hers', \"needn't\", \"mustn't\", 'didn', 'was', 'your', 're', 'into', 'they', 'for', 'than', 'we', 'them', 'between', 'i', 'won', 'theirs', 'it', 'don', 'y', 'why', 'of', 'with', 'having', 'then', 'these', 'had', 'each', \"wouldn't\", 'not', 'doesn', 'so', 'you', 'my', \"you're\", 'there', 'can', 'am', 'a', 'needn', 'from', 'being', 'herself', 'more', 'have', 'their', 'at', 'are', 'll', 'until', 'that', 'hadn', 'over', 'just', \"it's\", 'against', \"haven't\", 'this', 'because', 'here', 'same', 'should', 'o', 'mustn', 'yourselves', \"she's\", \"you'd\", 'once', \"weren't\", 'under', 'in', 'to', 'ain', 'all', 'any', 'yours', 'ourselves', 'or', 'who', 'below', 'ours', 'the', 'down', 'too', 'me', 'before', 'very', 've', 'shan', 'mightn', 'most', 'its', 'further', 'has', 'haven', \"that'll\", 'couldn', \"mightn't\", 'other', 'our', 'and', 'aren', 'doing', 'when', 'm', \"hadn't\", 'above', \"you'll\", \"didn't\"}\n"
     ]
    }
   ],
   "source": [
    "# Storing all the stopwords into variables\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510be9c6-84bb-4922-8a8d-b425962155be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,entry in enumerate(disaster['text']):\n",
    "    Final_words = []\n",
    "    word_lemmstized = WordNetLemmatizer()\n",
    "    for word,tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_final = word_lemmstized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_final)\n",
    "    disaster.loc[index,'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045414f1-6808-4e42-b743-d20fde0b49cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[communal, violence, in, bhainsa, ,, telangana...</td>\n",
       "      <td>1</td>\n",
       "      <td>['communal', 'violence', 'bhainsa', 'telangana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[telangana, :, section, 144, has, been, impose...</td>\n",
       "      <td>1</td>\n",
       "      <td>['telangana', 'section', 'imposed', 'bhainsa',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[arsonist, sets, cars, ablaze, at, dealership,...</td>\n",
       "      <td>1</td>\n",
       "      <td>['arsonist', 'set', 'car', 'ablaze', 'dealersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[arsonist, sets, cars, ablaze, at, dealership,...</td>\n",
       "      <td>1</td>\n",
       "      <td>['arsonist', 'set', 'car', 'ablaze', 'dealersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[``, lord, jesus, ,, your, love, brings, freed...</td>\n",
       "      <td>0</td>\n",
       "      <td>['lord', 'jesus', 'love', 'brings', 'freedom',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  [communal, violence, in, bhainsa, ,, telangana...       1   \n",
       "1  [telangana, :, section, 144, has, been, impose...       1   \n",
       "2  [arsonist, sets, cars, ablaze, at, dealership,...       1   \n",
       "3  [arsonist, sets, cars, ablaze, at, dealership,...       1   \n",
       "4  [``, lord, jesus, ,, your, love, brings, freed...       0   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['communal', 'violence', 'bhainsa', 'telangana...  \n",
       "1  ['telangana', 'section', 'imposed', 'bhainsa',...  \n",
       "2  ['arsonist', 'set', 'car', 'ablaze', 'dealersh...  \n",
       "3  ['arsonist', 'set', 'car', 'ablaze', 'dealersh...  \n",
       "4  ['lord', 'jesus', 'love', 'brings', 'freedom',...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9e9de-b8ff-423d-ae73-9beff6656011",
   "metadata": {},
   "source": [
    "# LSTM Based Model Building & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edd05b1b-0558-4c46-9d88-75c12c9ef307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import preprocessing\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection,naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import pad_sequences\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b667016d-659a-4e4d-96cb-25c1802801b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X,Test_X,Train_Y,Test_Y = sklearn.model_selection.train_test_split(disaster['text_final'],disaster['target'],test_size = 0.3)\n",
    "encoder = LabelEncoder()\n",
    "Train_Y = encoder.fit_transform(Train_Y)\n",
    "Test_Y = encoder.fit_transform(Test_Y)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features = 5000)\n",
    "Tfidf_vect.fit(disaster['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(Train_X)\n",
    "sequences = tok.texts_to_sequences(Train_X)\n",
    "sequences_matrix = keras.utils.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4142001-ff81-4312-8ed4-95789c0c829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b3fa795-4646-43a7-97eb-e79385920613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 150, 50)           50000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                29440     \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98f38977-a416-40dc-85ad-b06b1214dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 3.4840 - val_accuracy: 0.7927\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 3.6460 - val_accuracy: 0.7877\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 3.6216 - val_accuracy: 0.8028\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 3.9567 - val_accuracy: 0.8053\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 5s 100ms/step - loss: 0.0076 - accuracy: 0.9969 - val_loss: 3.7718 - val_accuracy: 0.8040\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 3.7531 - val_accuracy: 0.8059\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 3.8260 - val_accuracy: 0.8028\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 3.7744 - val_accuracy: 0.8003\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 3.9204 - val_accuracy: 0.8040\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 3.7357 - val_accuracy: 0.8046\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 3.9487 - val_accuracy: 0.8084\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.0057 - accuracy: 0.9975 - val_loss: 3.7715 - val_accuracy: 0.7940\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 3.5957 - val_accuracy: 0.8059\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 5s 109ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 4.0136 - val_accuracy: 0.8015\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 3.6197 - val_accuracy: 0.7915\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.0070 - accuracy: 0.9967 - val_loss: 5.1595 - val_accuracy: 0.8059\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 0.1660 - accuracy: 0.9782 - val_loss: 3.3483 - val_accuracy: 0.8021\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 3.3300 - val_accuracy: 0.7952\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 3.5752 - val_accuracy: 0.8053\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 6s 113ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 3.2235 - val_accuracy: 0.7858\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(sequences_matrix,Train_Y,batch_size=128,epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebda81da-47ee-435f-8ecd-1ead5a65117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(Test_X)\n",
    "test_sequences_matrix = keras.utils.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d0f924f-47cb-4e52-9d1f-01a1d058829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 2s 19ms/step - loss: 2.9150 - accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a36d5c80-4be2-4cc9-b6b8-6700c5a7a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 2.915\n",
      "  Accuracy: 0.803\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5315f5f7-a08d-4cc2-8763-33c9c8ad3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'history_LSTM_20epoch.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0583ba2c-6566-44c8-af66-b40909af7731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\activation\n",
      "......vars\n",
      "...layers\\activation_1\n",
      "......vars\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-29 15:48:10         4104\n",
      "metadata.json                                  2023-03-29 15:48:10           64\n",
      "variables.h5                                   2023-03-29 15:48:11       803680\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'LSTM_80.30acc.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6d719-de93-4fc4-b545-0ef033dfde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d28b9-f440-4e0d-8ccf-d4078cf5804c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
